{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def func_attention(query, context, gamma1):\n",
    "    \"\"\"\n",
    "    query: batch x ndf x queryL\n",
    "    context: batch x ndf x ih x iw (sourceL=ihxiw)\n",
    "    mask: batch_size x sourceL\n",
    "    \"\"\"\n",
    "    batch_size, queryL = query.size(0), query.size(2)\n",
    "    ih, iw = context.size(2), context.size(3)\n",
    "    sourceL = ih * iw\n",
    "\n",
    "    # --> batch x sourceL x ndf\n",
    "    context = context.view(batch_size, -1, sourceL)\n",
    "    contextT = torch.transpose(context, 1, 2).contiguous()\n",
    "\n",
    "    # Get attention\n",
    "    # (batch x sourceL x ndf)(batch x ndf x queryL)\n",
    "    # -->batch x sourceL x queryL\n",
    "    attn = torch.bmm(contextT, query) # Eq. (7) in AttnGAN paper\n",
    "    # --> batch*sourceL x queryL\n",
    "    attn = attn.view(batch_size*sourceL, queryL)\n",
    "    attn = nn.Softmax()(attn)  # Eq. (8)\n",
    "\n",
    "    # --> batch x sourceL x queryL\n",
    "    attn = attn.view(batch_size, sourceL, queryL)\n",
    "    # --> batch*queryL x sourceL\n",
    "    attn = torch.transpose(attn, 1, 2).contiguous()\n",
    "    attn = attn.view(batch_size*queryL, sourceL)\n",
    "    #  Eq. (9)\n",
    "    attn = attn * gamma1\n",
    "    attn = nn.Softmax()(attn)\n",
    "    attn = attn.view(batch_size, queryL, sourceL)\n",
    "    # --> batch x sourceL x queryL\n",
    "    attnT = torch.transpose(attn, 1, 2).contiguous()\n",
    "\n",
    "    # (batch x ndf x sourceL)(batch x sourceL x queryL)\n",
    "    # --> batch x ndf x queryL\n",
    "    weightedContext = torch.bmm(context, attnT)\n",
    "    \n",
    "    return weightedContext, attn.view(batch_size, -1, ih, iw)\n",
    "\n",
    "\n",
    "def cosine_similarity(x1, x2, dim=1, eps=1e-8):\n",
    "    \"\"\"Returns cosine similarity between x1 and x2, computed along dim.\n",
    "    \"\"\"\n",
    "    w12 = torch.sum(x1 * x2, dim)\n",
    "    w1 = torch.norm(x1, 2, dim)\n",
    "    w2 = torch.norm(x2, 2, dim)\n",
    "    return (w12 / (w1 * w2).clamp(min=eps)).squeeze()\n",
    "\n",
    "\n",
    "def words_loss(img_features, words_emb, labels, batch_size, class_ids):\n",
    "    \"\"\"\n",
    "        words_emb(query): batch x nef x seq_len\n",
    "        img_features(context): batch x nef x 17 x 17\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "    att_maps = []\n",
    "    similarities = []\n",
    "    for i in range(batch_size):\n",
    "        if class_ids is not None:\n",
    "            mask = (class_ids == class_ids[i]).astype(np.uint8)\n",
    "            mask[i] = 0\n",
    "            masks.append(mask.reshape((1, -1)))\n",
    "                \n",
    "        words_num = words_emb.shape[2]\n",
    "                \n",
    "        # -> 1 x nef x words_num\n",
    "        word = words_emb[i, :, :words_num].unsqueeze(0).contiguous()\n",
    "        # -> batch_size x nef x words_num\n",
    "        word = word.repeat(batch_size, 1, 1)\n",
    "        # batch x nef x 17*17\n",
    "        \n",
    "        context = img_features\n",
    "        \"\"\"\n",
    "            word(query): batch x nef x words_num\n",
    "            context: batch x nef x 17 x 17\n",
    "            weiContext: batch x nef x words_num\n",
    "            attn: batch x words_num x 17 x 17\n",
    "        \"\"\"\n",
    "        weiContext, attn = func_attention(word, context,5)\n",
    "\n",
    "        att_maps.append(attn[i].unsqueeze(0).contiguous())\n",
    "        # --> batch_size x words_num x nef\n",
    "        word = word.transpose(1, 2).contiguous()\n",
    "        weiContext = weiContext.transpose(1, 2).contiguous()\n",
    "        \n",
    "        # --> batch_size*words_num x nef\n",
    "        word = word.view(batch_size * words_num, -1)\n",
    "        weiContext = weiContext.view(batch_size * words_num, -1)\n",
    "        \n",
    "        # -->batch_size*words_num\n",
    "        row_sim = cosine_similarity(word, weiContext)\n",
    "        # --> batch_size x words_num\n",
    "        row_sim = row_sim.view(batch_size, words_num)\n",
    "\n",
    "        # Eq. (10)\n",
    "        row_sim.mul_(5).exp_()\n",
    "        row_sim = row_sim.sum(dim=1, keepdim=True)\n",
    "        row_sim = torch.log(row_sim)\n",
    "\n",
    "        # --> 1 x batch_size\n",
    "        # similarities(i, j): the similarity between the i-th image and the j-th text description\n",
    "        similarities.append(row_sim)\n",
    "\n",
    "    # batch_size x batch_size\n",
    "    similarities = torch.cat(similarities, 1)\n",
    "\n",
    "    if class_ids is not None:\n",
    "        masks = np.concatenate(masks, 0)\n",
    "        # masks: batch_size x batch_size\n",
    "        masks = torch.ByteTensor(masks).cuda()\n",
    "\n",
    "    similarities = similarities * 10\n",
    "\n",
    "    if class_ids is not None:\n",
    "        similarities.data.masked_fill_(masks, -float('inf'))\n",
    "   \n",
    "    similarities1 = similarities.transpose(0, 1)\n",
    "\n",
    "    if labels is not None:\n",
    "        loss0 = nn.CrossEntropyLoss()(similarities, labels)\n",
    "        loss1 = nn.CrossEntropyLoss()(similarities1, labels)\n",
    "    else:\n",
    "        loss0, loss1 = None, None\n",
    "    return loss0, loss1, att_maps\n",
    "\n",
    "w_loss0, w_loss1, attn_maps = words_loss(img_features, word_emb, label, batch_size, class_ids)\n",
    "\n",
    "\n",
    "def sent_loss(cnn_code, rnn_code, labels, class_ids,\n",
    "              batch_size, eps=1e-8):\n",
    "    # ### Mask mis-match samples  ###\n",
    "    # that come from the same class as the real sample ###\n",
    "    masks = []\n",
    "    if class_ids is not None:\n",
    "        for i in range(batch_size):\n",
    "            mask = (class_ids == class_ids[i]).astype(np.uint8)\n",
    "            mask[i] = 0\n",
    "            masks.append(mask.reshape((1, -1)))\n",
    "        masks = np.concatenate(masks, 0)\n",
    "        # masks: batch_size x batch_size\n",
    "        masks = torch.ByteTensor(masks).cuda()\n",
    "\n",
    "    # --> seq_len x batch_size x nef\n",
    "    if cnn_code.dim() == 2:\n",
    "        cnn_code = cnn_code.unsqueeze(0)\n",
    "        rnn_code = rnn_code.unsqueeze(0)\n",
    "\n",
    "    # cnn_code_norm / rnn_code_norm: seq_len x batch_size x 1\n",
    "    cnn_code_norm = torch.norm(cnn_code, 2, dim=2, keepdim=True)\n",
    "    rnn_code_norm = torch.norm(rnn_code, 2, dim=2, keepdim=True)\n",
    "        \n",
    "    # scores* / norm*: seq_len x batch_size x batch_size\n",
    "    scores0 = torch.bmm(cnn_code, rnn_code.transpose(1, 2))\n",
    "    norm0 = torch.bmm(cnn_code_norm, rnn_code_norm.transpose(1, 2))\n",
    "    scores0 = scores0 / norm0.clamp(min=eps) * 10\n",
    "    \n",
    "    # --> batch_size x batch_size\n",
    "    scores0 = scores0.squeeze()\n",
    "\n",
    "    if class_ids is not None:\n",
    "        scores0.data.masked_fill_(masks, -float('inf'))\n",
    "    scores1 = scores0.transpose(0, 1)\n",
    "    \n",
    "    if labels is not None:\n",
    "        loss0 = nn.CrossEntropyLoss()(scores0, labels)\n",
    "        loss1 = nn.CrossEntropyLoss()(scores1, labels)\n",
    "    else:\n",
    "        loss0, loss1 = None, None\n",
    "    return loss0, loss1\n",
    "\n",
    "s_loss0, s_loss1 = sent_loss(img_sent_code, sent_emb, label, class_ids, batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
