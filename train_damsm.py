{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from torch.autograd import Variable\n",
    "label = Variable(torch.LongTensor(range(batch_size))).cuda()  # will be used in train loop\n",
    "\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), image_encoder.parameters()), lr, betas=(0.5, 0.999))\n",
    "num_epochs = 100\n",
    "UPDATE_INTERVAL = 5\n",
    "\n",
    "num_images = 9429\n",
    "for epoch in range(0, num_epochs):\n",
    "    s_total_loss0 = 0\n",
    "    s_total_loss1 = 0\n",
    "    w_total_loss0 = 0\n",
    "    w_total_loss1 = 0\n",
    "    for i in range(num_images // batch_size):\n",
    "        x, y, class_ids = next(loader.get_data(True))\n",
    "        caption = y[:,np.random.randint(0,10),:]\n",
    "\n",
    "        model.zero_grad()\n",
    "        image_encoder.zero_grad()\n",
    "        \n",
    "        words_features, sent_code = image_encoder(x)\n",
    "        \n",
    "        model.hidden = model.init_hidden(batch_size)\n",
    "        words_emb, sent_emb = model.forward(caption)\n",
    "        \n",
    "#         print(words_emb.shape, sent_emb.shape, words_features.shape, sent_code.shape)\n",
    "        \n",
    "        w_loss0, w_loss1, attn_maps = words_loss(words_features, words_emb, label, batch_size, class_ids)\n",
    "    \n",
    "        w_total_loss0 += w_loss0.data\n",
    "        w_total_loss1 += w_loss1.data\n",
    "        loss = w_loss0 + w_loss1\n",
    "\n",
    "        s_loss0, s_loss1 = sent_loss(sent_code, sent_emb, label, class_ids, batch_size)\n",
    "        loss += s_loss0 + s_loss1\n",
    "        s_total_loss0 += s_loss0.data\n",
    "        s_total_loss1 += s_loss1.data\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm(model.parameters(), 0.25)\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % UPDATE_INTERVAL == 0:\n",
    "        \n",
    "            s_cur_loss0 = s_total_loss0.item() / UPDATE_INTERVAL\n",
    "            s_cur_loss1 = s_total_loss1.item() / UPDATE_INTERVAL\n",
    "\n",
    "            w_cur_loss0 = w_total_loss0.item() / UPDATE_INTERVAL\n",
    "            w_cur_loss1 = w_total_loss1.item() / UPDATE_INTERVAL\n",
    "\n",
    "            print(s_cur_loss0, s_cur_loss1,w_cur_loss0, w_cur_loss1)\n",
    "            s_total_loss0 = 0\n",
    "            s_total_loss1 = 0\n",
    "            w_total_loss0 = 0\n",
    "            w_total_loss1 = 0\n",
    "        \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
